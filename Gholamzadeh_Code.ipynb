{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ma-gym\n",
        "!pip install pygame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWHYP-49DcD5",
        "outputId": "854fc1e5-37ea-4088-94f2-d222c7412982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ma-gym in /usr/local/lib/python3.8/dist-packages (0.0.12)\n",
            "Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from ma-gym) (1.7.3)\n",
            "Requirement already satisfied: gym<=0.20.0,>=0.19.0 in /usr/local/lib/python3.8/dist-packages (from ma-gym) (0.20.0)\n",
            "Requirement already satisfied: pyglet<=1.5.27,>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from ma-gym) (1.5.27)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.8/dist-packages (from ma-gym) (1.21.6)\n",
            "Requirement already satisfied: cloudpickle==2.0.0 in /usr/local/lib/python3.8/dist-packages (from ma-gym) (2.0.0)\n",
            "Requirement already satisfied: pillow>=7.2.0 in /usr/local/lib/python3.8/dist-packages (from ma-gym) (9.3.0)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from ma-gym) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.8/dist-packages (2.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import ma_gym\n",
        "from ma_gym.envs.utils.action_space import MultiAgentActionSpace\n",
        "from ma_gym.envs.utils.observation_space import MultiAgentObservationSpace\n",
        "from pygame.event import pump\n",
        "import pygame\n",
        "import math"
      ],
      "metadata": {
        "id": "7HHeCM-I95Ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import output\n",
        "import time \n",
        "import os, sys"
      ],
      "metadata": {
        "id": "ntcAyZnDnHRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set SDL to use the dummy NULL video driver, \n",
        "#   so it doesn't need a windowing system.\n",
        "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\""
      ],
      "metadata": {
        "id": "rA9Rd12AnKxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLFutidA9qaD"
      },
      "outputs": [],
      "source": [
        "class MultiAgentEnv(gym.Env):\n",
        "    metadata = {\n",
        "        'render.modes' : ['human', 'rgb_array']\n",
        "    }\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        \n",
        "        #super(MultiAgentEnv, self).__init__()\n",
        "\n",
        "        self.fps = 5\n",
        "        self.fps_clock = pygame.time.Clock()\n",
        "        \n",
        "        self.screen = pygame.display.set_mode((500, 500))\n",
        "\n",
        "        self.ag = [pygame.image.load(r'car.png'),\n",
        "                   pygame.image.load(r'car1.png'),\n",
        "                   pygame.image.load(r'scar.png')]\n",
        "\n",
        "        self.img1 = pygame.image.load(\"store.png\")\n",
        "        self.img2 = pygame.image.load(\"store.png\")\n",
        "        self.img3 = pygame.image.load(\"placeholder.png\")\n",
        "        self.img4 = pygame.image.load(\"village.png\")\n",
        "        self.img5 = pygame.image.load(\"village.png\")\n",
        "        self.img6 = pygame.image.load(\"village.png\")\n",
        "\n",
        "        self.screen.blit(self.img2, (0,436))\n",
        "        self.screen.blit(self.img3, (200,200))\n",
        "        self.screen.blit(self.img4, (436,0))\n",
        "        self.screen.blit(self.img5, (436,186))\n",
        "        self.screen.blit(self.img6, (436,436))\n",
        "        \n",
        "        #display.set_caption('RUN')\n",
        "\n",
        "        self.total_time = 48\n",
        "        self.n_supplier = 2\n",
        "        self.n_hub = 1\n",
        "        self.n_customer = 3\n",
        "        \n",
        "        self.customer_or = np.zeros([self.n_supplier + 1, self.total_time+1, 2])\n",
        "\n",
        "        self.supplier_o = np.zeros([self.n_supplier + 1, 2])\n",
        "\n",
        "        self.capacity = 10\n",
        "\n",
        "        self.order_r = 0\n",
        "        self.order_d = 0\n",
        "\n",
        "       \n",
        "\n",
        "        self.n_agents = 3\n",
        "        self.agents = [\"agent_\" + str(r) for r in range(self.n_agents)]\n",
        "        self.agent_name_mapping = dict(zip(self.agents, list(range(self.n_agents))))\n",
        "\n",
        "        self.xy = np.zeros([self.n_agents + 1, 2])\n",
        "\n",
        "        self.x = [0,0,0,200,436,436,436]\n",
        "        self.y = [0,0,436,200,0,186,436]\n",
        "\n",
        "        self.m_speed = 10\n",
        "        self.dis = np.array([[0,0,0,0,0,0,0],\n",
        "                             [0,0,15,30,0,0,0],\n",
        "                             [0,15,0,20,0,0,0],\n",
        "                             [0,30,20,0,25,40,15],\n",
        "                             [0,0,0,25,0,15,0],\n",
        "                             [0,0,0,40,15,0,10],\n",
        "                             [0,0,0,15,0,10,0],])\n",
        "\n",
        "\n",
        "        self.obs_dim = (self.n_supplier * 2) + 8\n",
        "        self.state_dim = (self.n_supplier * 2) + 8 * self.n_agents\n",
        "\n",
        "        self.agent_v = np.zeros(self.n_agents)\n",
        "        self.agent_pr = np.zeros(self.n_agents)\n",
        "        self.agent_oo = np.zeros(self.n_agents)\n",
        "        self.agent_p = np.zeros(self.n_agents)\n",
        "        self.agent_dd = np.zeros(self.n_agents)\n",
        "\n",
        "        box_lows = np.zeros(self.state_dim)\n",
        "        box_highs = np.hstack([\n",
        "            np.repeat(self.n_customer + self.n_hub + self.n_supplier, 1),\n",
        "            np.repeat(10, 1),\n",
        "            np.repeat(self.n_customer + self.n_hub + self.n_supplier, 1),\n",
        "            np.repeat(10, 1),\n",
        "            np.repeat(self.m_speed, 1),\n",
        "            np.repeat(self.n_customer + self.n_hub + self.n_supplier, 1),\n",
        "            np.repeat(self.n_customer + self.n_hub + self.n_supplier, 1),\n",
        "            np.repeat(10, 1),\n",
        "            np.repeat(10, 1),\n",
        "            np.repeat(self.n_customer + self.n_hub + self.n_supplier, 1),\n",
        "            np.repeat(10, 1),\n",
        "            np.repeat(self.n_customer + self.n_hub + self.n_supplier, 1),\n",
        "            np.repeat(self.m_speed, 1),\n",
        "            np.repeat(self.n_customer + self.n_hub + self.n_supplier, 1),\n",
        "            np.repeat(self.n_customer + self.n_hub + self.n_supplier, 1),\n",
        "            np.repeat(10, 1),\n",
        "            np.repeat(10, 1),\n",
        "            np.repeat(self.n_customer + self.n_hub + self.n_supplier, 1),\n",
        "            np.repeat(10, 1),\n",
        "            np.repeat(self.n_customer + self.n_hub + self.n_supplier, 1),\n",
        "            np.repeat(self.m_speed, 1),\n",
        "            np.repeat(self.n_customer + self.n_hub + self.n_supplier, 1),\n",
        "            np.repeat(self.n_customer + self.n_hub + self.n_supplier, 1),\n",
        "            np.repeat(10, 1),\n",
        "            np.repeat(10, 1),\n",
        "            np.repeat(self.n_customer + self.n_hub + self.n_supplier, 1),\n",
        "            np.repeat(10, 1),\n",
        "            np.repeat(self.n_customer + self.n_hub + self.n_supplier, 1),\n",
        "        ])\n",
        "\n",
        "        box_low = np.zeros(self.obs_dim)\n",
        "        box_high = np.hstack([\n",
        "            np.repeat(self.n_customer + self.n_hub + self.n_supplier, 1),\n",
        "            np.repeat(10, 1),\n",
        "            np.repeat(self.n_customer + self.n_hub + self.n_supplier, 1),\n",
        "            np.repeat(10, 1),\n",
        "            np.repeat(self.m_speed, 1),\n",
        "            np.repeat(self.n_customer + self.n_hub + self.n_supplier, 1),\n",
        "            np.repeat(self.n_customer + self.n_hub + self.n_supplier, 1),\n",
        "            np.repeat(10, 1),\n",
        "            np.repeat(10, 1),\n",
        "            np.repeat(self.n_customer + self.n_hub + self.n_supplier, 1),\n",
        "            np.repeat(10, 1),\n",
        "            np.repeat(self.n_customer + self.n_hub + self.n_supplier, 1),\n",
        "        ])\n",
        "\n",
        "        self.observation_space = MultiAgentObservationSpace([gym.spaces.Box(low=box_low, high=box_high, dtype=np.float64,)\n",
        "                                                             for _ in range(self.n_agents)])\n",
        "        \n",
        "#        self.observation_spaces = dict(\n",
        " #           zip(\n",
        "  #              self.agents,\n",
        "   #             [\n",
        "    #                gym.spaces.Box(\n",
        "     #                   low=box_low,\n",
        "      #                  high=box_high,\n",
        "       #                 dtype=np.float,\n",
        "        #            )\n",
        "         #       ] * self.n_agents\n",
        "          #  )\n",
        "        #)\n",
        "\n",
        "        #self.action_space = MultiAgentActionSpace([gym.spaces.MultiDiscrete([self.n_customer + self.n_hub + self.n_supplier+1, 2]) for _ in range(self.n_agents)])\n",
        "        self.action_space = MultiAgentActionSpace([gym.spaces.Discrete((self.n_customer + self.n_hub + self.n_supplier+1)* 2) for _ in range(self.n_agents)])\n",
        "\n",
        "        #self.action_spaces = dict(\n",
        "         #       zip(\n",
        "          #          self.agents,\n",
        "           #         [gym.spaces.MultiDiscrete([self.n_customer + self.n_hub + self.n_supplier, 1])] * self.n_agents,\n",
        "            #    )\n",
        "            #)\n",
        "        \n",
        "        self.state_space = gym.spaces.Box(\n",
        "                        low=box_lows,\n",
        "                        high=box_highs,\n",
        "                        dtype=np.float64,\n",
        "                    )\n",
        "    \n",
        "    def action_space_sample(self):\n",
        "        return [agent_action_space.sample() for agent_action_space in self.action_space]\n",
        "\n",
        "    #def observation_space(self, agent):\n",
        "    #    return self.observation_spaces[agent]\n",
        "\n",
        "    #def action_space(self, agent):\n",
        "    #    return self.action_spaces[agent]\n",
        "\n",
        "    #def seed(self, seed=None):\n",
        "    #    self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
        "\n",
        "    def step(self, action):\n",
        "      #pump()\n",
        "\n",
        "      assert len(action) == self.n_agents\n",
        "\n",
        "      obs_n = []\n",
        "      reward_n = []\n",
        "      done_n = []\n",
        "      info_n = {'n': []}\n",
        "      \n",
        "      for i, agent in enumerate(self.agents):\n",
        "        rew = 0\n",
        "        t=0\n",
        "        act = action[i]\n",
        "        d = 0\n",
        "        \n",
        "        if act%7 == 0:\n",
        "          if self.agent_v[i] > 0:\n",
        "            t = self.traffic[self.agent_o[i]][self.agent_d[i]]\n",
        "            self.agent_v[i] = self.m_speed * (1 - (t/self.capacity))\n",
        "            self.agent_pr[i] += self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            d = self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            if self.agent_pr[i] >=1:\n",
        "              self.agent_v[i] = 0\n",
        "              self.agent_o[i] = self.agent_d[i]\n",
        "              t = 0\n",
        "              self.agent_pr[i] = 1\n",
        "              rew = -1\n",
        "              if act//7 == 1:\n",
        "                if self.agent_oo[i] == self.agent_dd[i] == self.agent_p[i] == 0 and ((self.agent_d[i] == 1 and self.supplier_o[1][1]>0) or (self.agent_d[i] == 2 and self.supplier_o[2][1]>0)):\n",
        "                  self.agent_oo[i] = self.agent_d[i]\n",
        "                  self.agent_dd[i] = self.supplier_o[self.agent_d[i]][0] \n",
        "                  self.agent_p[i] = self.supplier_o[self.agent_d[i]][1]\n",
        "                  self.supplier_o[self.agent_d[i]][0] = 0\n",
        "                  self.supplier_o[self.agent_d[i]][1] = 0\n",
        "                  self.order_r += 1\n",
        "                  rew += 5\n",
        "                else:\n",
        "                  rew = -1\n",
        "              elif act//7 == 0:\n",
        "                if self.agent_oo[i] == self.agent_dd[i] == self.agent_p[i] > 0 and self.agent_d[i] == self.agent_dd[i]:\n",
        "                  self.agent_oo[i] = 0\n",
        "                  self.agent_dd[i] = 0\n",
        "                  self.order_d += 1\n",
        "                  rew += self.agent_p[i]\n",
        "                  self.agent_p[i] = 0\n",
        "                else:\n",
        "                  rew += -1\n",
        "            else:\n",
        "              rew += -1\n",
        "\n",
        "        elif act%7 == 1:\n",
        "          if self.agent_o[i] == self.agent_d[i] == 2 or self.agent_o[i] == self.agent_d[i] == 3:\n",
        "            self.agent_d[i] = 1\n",
        "            t = self.traffic[self.agent_o[i]][self.agent_d[i]]\n",
        "            self.agent_v[i] = self.m_speed * (1 - (t/self.capacity))\n",
        "            self.agent_pr[i] = self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            d = self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            rew += -1\n",
        "          elif self.agent_o[i] != self.agent_d[i]:\n",
        "            t = self.traffic[self.agent_o[i]][self.agent_d[i]]\n",
        "            self.agent_v[i] = self.m_speed * (1 - (t/self.capacity))\n",
        "            self.agent_pr[i] += self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            d = self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            if self.agent_pr[i] >=1:\n",
        "              self.agent_v[i] = 0\n",
        "              self.agent_o[i] = self.agent_d[i]\n",
        "              t = 0\n",
        "              self.agent_pr[i] = 1\n",
        "              rew = -1\n",
        "              if act//7 == 1:\n",
        "                if self.agent_oo[i] == self.agent_dd[i] == self.agent_p[i] == 0 and ((self.agent_d[i] == 1 and self.supplier_o[1][1]>0) or (self.agent_d[i] == 2 and self.supplier_o[2][1]>0)):\n",
        "                  self.agent_oo[i] = self.agent_d[i]\n",
        "                  self.agent_dd[i] = self.supplier_o[self.agent_d[i]][0] \n",
        "                  self.agent_p[i] = self.supplier_o[self.agent_d[i]][1]\n",
        "                  self.supplier_o[self.agent_d[i]][0] = 0\n",
        "                  self.supplier_o[self.agent_d[i]][1] = 0\n",
        "                  self.order_r += 1\n",
        "                  rew += 5\n",
        "                else:\n",
        "                  rew += -20\n",
        "              elif act//7 == 0:\n",
        "                if self.agent_oo[i] == self.agent_dd[i] == self.agent_p[i] > 0 and self.agent_d[i] == self.agent_dd[i]:\n",
        "                  self.agent_oo[i] = 0\n",
        "                  self.agent_dd[i] = 0\n",
        "                  self.order_d += 1\n",
        "                  rew += self.agent_p[i]\n",
        "                  self.agent_p[i] = 0\n",
        "                else:\n",
        "                  rew += -20\n",
        "            else:\n",
        "                rew += -20\n",
        "        elif act%7 == 2:\n",
        "          if self.agent_o[i] == self.agent_d[i] == 1 or self.agent_o[i] == self.agent_d[i] == 3:\n",
        "            self.agent_d[i] = 2\n",
        "            t = self.traffic[self.agent_o[i]][self.agent_d[i]]\n",
        "            self.agent_v[i] = self.m_speed * (1 - (t/self.capacity))\n",
        "            self.agent_pr[i] = self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            d = self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            rew += -1\n",
        "          elif self.agent_o[i] != self.agent_d[i]:\n",
        "            t = self.traffic[self.agent_o[i]][self.agent_d[i]]\n",
        "            self.agent_v[i] = self.m_speed * (1 - (t/self.capacity)) \n",
        "            self.agent_pr[i] += self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            d = self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            if self.agent_pr[i] >=1:\n",
        "              self.agent_v[i] = 0\n",
        "              self.agent_o[i] = self.agent_d[i]\n",
        "              t = 0\n",
        "              self.agent_pr[i] = 1\n",
        "              rew = -1\n",
        "              if act//7 == 1:\n",
        "                if self.agent_oo[i] == self.agent_dd[i] == self.agent_p[i] == 0 and ((self.agent_d[i] == 1 and self.supplier_o[1][1]>0) or (self.agent_d[i] == 2 and self.supplier_o[2][1]>0)):\n",
        "                  self.agent_oo[i] = self.agent_d[i]\n",
        "                  self.agent_dd[i] = self.supplier_o[self.agent_d[i]][0] \n",
        "                  self.agent_p[i] = self.supplier_o[self.agent_d[i]][1]\n",
        "                  self.supplier_o[self.agent_d[i]][0] = 0\n",
        "                  self.supplier_o[self.agent_d[i]][1] = 0\n",
        "                  self.order_r += 1\n",
        "                  rew += 5\n",
        "                else:\n",
        "                  rew += -20\n",
        "              elif act//7 == 0:\n",
        "                if self.agent_oo[i] == self.agent_dd[i] == self.agent_p[i] > 0 and self.agent_d[i] == self.agent_dd[i]:\n",
        "                  self.agent_oo[i] = 0\n",
        "                  self.agent_dd[i] = 0\n",
        "                  self.order_d += 1\n",
        "                  rew += self.agent_p[i]\n",
        "                  self.agent_p[i] = 0\n",
        "                else:\n",
        "                  rew += -20\n",
        "            else:\n",
        "                rew += -20\n",
        "        \n",
        "        elif act%7 == 3:\n",
        "          if self.agent_o[i] == self.agent_d[i] == 1 or self.agent_o[i] == self.agent_d[i] == 2 or self.agent_o[i] == self.agent_d[i] == 4 or self.agent_o[i] == self.agent_d[i] == 5 or self.agent_o[i] == self.agent_d[i] == 6:\n",
        "            self.agent_d[i] = 3\n",
        "            t = self.traffic[self.agent_o[i]][self.agent_d[i]]\n",
        "            self.agent_v[i] = self.m_speed * (1 - (t/self.capacity))\n",
        "            self.agent_pr[i] = self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            d = self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            rew += -1\n",
        "          elif self.agent_o[i] != self.agent_d[i]:\n",
        "            t = self.traffic[self.agent_o[i]][self.agent_d[i]]\n",
        "            self.agent_v[i] = self.m_speed * (1 - (t/self.capacity)) \n",
        "            self.agent_pr[i] += self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            d = self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            if self.agent_pr[i] >=1:\n",
        "              self.agent_v[i] = 0\n",
        "              self.agent_o[i] = self.agent_d[i]\n",
        "              t = 0\n",
        "              self.agent_pr[i] = 1\n",
        "              rew = -1\n",
        "              if act//7 == 1:\n",
        "                if self.agent_oo[i] == self.agent_dd[i] == self.agent_p[i] == 0 and ((self.agent_d[i] == 1 and self.supplier_o[1][1]>0) or (self.agent_d[i] == 2 and self.supplier_o[2][1]>0)):\n",
        "                  self.agent_oo[i] = self.agent_d[i]\n",
        "                  self.agent_dd[i] = self.supplier_o[self.agent_d[i]][0] \n",
        "                  self.agent_p[i] = self.supplier_o[self.agent_d[i]][1]\n",
        "                  self.supplier_o[self.agent_d[i]][0] = 0\n",
        "                  self.supplier_o[self.agent_d[i]][1] = 0\n",
        "                  self.order_r += 1\n",
        "                  rew += 5\n",
        "                else:\n",
        "                  rew += -20\n",
        "              elif act//7 == 0:\n",
        "                if self.agent_oo[i] == self.agent_dd[i] == self.agent_p[i] > 0 and self.agent_d[i] == self.agent_dd[i]:\n",
        "                  self.agent_oo[i] = 0\n",
        "                  self.agent_dd[i] = 0\n",
        "                  self.order_d += 1\n",
        "                  rew += self.agent_p[i]\n",
        "                  self.agent_p[i] = 0\n",
        "                else:\n",
        "                  rew += -20\n",
        "            else:\n",
        "                rew += -20\n",
        "\n",
        "        elif act%7 == 4:\n",
        "          if self.agent_o[i] == self.agent_d[i] == 5 or self.agent_o[i] == self.agent_d[i] == 3:\n",
        "            self.agent_d[i] = 4\n",
        "            t = self.traffic[self.agent_o[i]][self.agent_d[i]]\n",
        "            self.agent_v[i] = self.m_speed * (1 - (t/self.capacity))\n",
        "            self.agent_pr[i] = self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            d = self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            rew += -1\n",
        "          elif self.agent_o[i] != self.agent_d[i]:\n",
        "            t = self.traffic[self.agent_o[i]][self.agent_d[i]]\n",
        "            self.agent_v[i] = self.m_speed * (1 - (t/self.capacity))\n",
        "            self.agent_pr[i] += self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            d = self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            if self.agent_pr[i] >=1:\n",
        "              self.agent_v[i] = 0\n",
        "              self.agent_o[i] = self.agent_d[i]\n",
        "              t = 0\n",
        "              self.agent_pr[i] = 1\n",
        "              rew = -1\n",
        "              if act//7 == 1:\n",
        "                if self.agent_oo[i] == self.agent_dd[i] == self.agent_p[i] == 0 and ((self.agent_d[i] == 1 and self.supplier_o[1][1]>0) or (self.agent_d[i] == 2 and self.supplier_o[2][1]>0)):\n",
        "                  self.agent_oo[i] = self.agent_d[i]\n",
        "                  self.agent_dd[i] = self.supplier_o[self.agent_d[i]][0] \n",
        "                  self.agent_p[i] = self.supplier_o[self.agent_d[i]][1]\n",
        "                  self.supplier_o[self.agent_d[i]][0] = 0\n",
        "                  self.supplier_o[self.agent_d[i]][1] = 0\n",
        "                  self.order_r += 1\n",
        "                  rew += 5\n",
        "                else:\n",
        "                  rew += -20\n",
        "              elif act//7 == 0:\n",
        "                if self.agent_oo[i] == self.agent_dd[i] == self.agent_p[i] > 0 and self.agent_d[i] == self.agent_dd[i]:\n",
        "                  self.agent_oo[i] = 0\n",
        "                  self.agent_dd[i] = 0\n",
        "                  self.order_d += 1\n",
        "                  rew += self.agent_p[i]\n",
        "                  self.agent_p[i] = 0\n",
        "                else:\n",
        "                  rew += -20\n",
        "            else:\n",
        "                rew += -20\n",
        "        \n",
        "        elif act%7 == 5:\n",
        "          if self.agent_o[i] == self.agent_d[i] == 4 or self.agent_o[i] == self.agent_d[i] == 3 or self.agent_o[i] == self.agent_d[i] == 6:\n",
        "            self.agent_d[i] = 5\n",
        "            t = self.traffic[self.agent_o[i]][self.agent_d[i]]\n",
        "            self.agent_v[i] = self.m_speed * (1 - (t/self.capacity))\n",
        "            self.agent_pr[i] = self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            d = self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            rew += -1\n",
        "          elif self.agent_o[i] != self.agent_d[i]:\n",
        "            t = self.traffic[self.agent_o[i]][self.agent_d[i]]\n",
        "            self.agent_v[i] = self.m_speed * (1 - (t/self.capacity))\n",
        "            self.agent_pr[i] += self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            d = self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            if self.agent_pr[i] >=1:\n",
        "              self.agent_v[i] = 0\n",
        "              self.agent_o[i] = self.agent_d[i]\n",
        "              t = 0\n",
        "              self.agent_pr[i] = 1\n",
        "              rew = -1\n",
        "              if act//7 == 1:\n",
        "                if self.agent_oo[i] == self.agent_dd[i] == self.agent_p[i] == 0 and ((self.agent_d[i] == 1 and self.supplier_o[1][1]>0) or (self.agent_d[i] == 2 and self.supplier_o[2][1]>0)):\n",
        "                  self.agent_oo[i] = self.agent_d[i]\n",
        "                  self.agent_dd[i] = self.supplier_o[self.agent_d[i]][0] \n",
        "                  self.agent_p[i] = self.supplier_o[self.agent_d[i]][1]\n",
        "                  self.supplier_o[self.agent_d[i]][0] = 0\n",
        "                  self.supplier_o[self.agent_d[i]][1] = 0\n",
        "                  self.order_r += 1\n",
        "                  rew += 5\n",
        "                else:\n",
        "                  rew += -20\n",
        "              elif act//7 == 0:\n",
        "                if self.agent_oo[i] == self.agent_dd[i] == self.agent_p[i] > 0 and self.agent_d[i] == self.agent_dd[i]:\n",
        "                  self.agent_oo[i] = 0\n",
        "                  self.agent_dd[i] = 0\n",
        "                  self.order_d += 1\n",
        "                  rew += self.agent_p[i]\n",
        "                  self.agent_p[i] = 0\n",
        "                else:\n",
        "                  rew += -20\n",
        "            else:\n",
        "                rew += -20\n",
        "        \n",
        "        elif act%7 == 6:\n",
        "          if self.agent_o[i] == self.agent_d[i] == 5 or self.agent_o[i] == self.agent_d[i] == 3:\n",
        "            self.agent_d[i] = 6\n",
        "            t = self.traffic[self.agent_o[i]][self.agent_d[i]]\n",
        "            self.agent_v[i] = self.m_speed * (1 - (t/self.capacity))\n",
        "            self.agent_pr[i] = self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            d = self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            rew += -1\n",
        "          elif self.agent_o[i] != self.agent_d[i]:\n",
        "            t = self.traffic[self.agent_o[i]][self.agent_d[i]]\n",
        "            self.agent_v[i] = self.m_speed * (1 - (t/self.capacity))\n",
        "            self.agent_pr[i] += self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            d = self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
        "            if self.agent_pr[i] >=1:\n",
        "              self.agent_v[i] = 0\n",
        "              self.agent_o[i] = self.agent_d[i]\n",
        "              t = 0\n",
        "              self.agent_pr[i] = 1\n",
        "              rew = -1\n",
        "              if act//7 == 1:\n",
        "                if self.agent_oo[i] == self.agent_dd[i] == self.agent_p[i] == 0 and ((self.agent_d[i] == 1 and self.supplier_o[1][1]>0) or (self.agent_d[i] == 2 and self.supplier_o[2][1]>0)):\n",
        "                  self.agent_oo[i] = self.agent_d[i]\n",
        "                  self.agent_dd[i] = self.supplier_o[self.agent_d[i]][0] \n",
        "                  self.agent_p[i] = self.supplier_o[self.agent_d[i]][1]\n",
        "                  self.supplier_o[self.agent_d[i]][0] = 0\n",
        "                  self.supplier_o[self.agent_d[i]][1] = 0\n",
        "                  self.order_r += 1\n",
        "                  rew += 5\n",
        "                else:\n",
        "                  rew += -20\n",
        "              elif act//7 == 0:\n",
        "                if self.agent_oo[i] == self.agent_dd[i] == self.agent_p[i] > 0 and self.agent_d[i] == self.agent_dd[i]:\n",
        "                  self.agent_oo[i] = 0\n",
        "                  self.agent_dd[i] = 0\n",
        "                  self.order_d += 1\n",
        "                  rew += self.agent_p[i]\n",
        "                  self.agent_p[i] = 0\n",
        "                else:\n",
        "                  rew += -20\n",
        "            else:\n",
        "                rew += -20\n",
        "        \n",
        "        ob = np.hstack([\n",
        "            self.supplier_o[1][0],\n",
        "            self.supplier_o[1][1],\n",
        "            self.supplier_o[2][0],\n",
        "            self.supplier_o[2][1],\n",
        "            self.agent_v[i],\n",
        "            self.agent_o[i],\n",
        "            self.agent_d[i],\n",
        "            self.agent_pr[i],\n",
        "            t,\n",
        "            self.agent_oo[i],\n",
        "            self.agent_p[i],\n",
        "            self.agent_dd[i]\n",
        "        ])\n",
        "\n",
        "        do = False\n",
        "\n",
        "        if self.agent_o[i] == self.agent_d[i]:\n",
        "          self.xy[i+1][0] += self.x[self.agent_o[i]] - self.xy[i+1][0]\n",
        "          self.xy[i+1][1] += self.y[self.agent_o[i]] - self.xy[i+1][1]\n",
        "        else:\n",
        "          \n",
        "          self.xy[i+1][0] += -(self.xy[i+1][0]-self.x[int(self.agent_d[i])])*d\n",
        "          self.xy[i+1][1] += -(self.xy[i+1][1]-self.y[int(self.agent_d[i])])*d\n",
        "\n",
        "        obs_n.append(ob)\n",
        "        reward_n.append(rew)\n",
        "        done_n.append(do)\n",
        "      \n",
        "      for i in range(self.n_supplier):\n",
        "        if self.supplier_o[i+1][1] == 0:\n",
        "          self.supplier_o[i+1][0] = self.customer_or[i+1][self.time][0]\n",
        "          self.supplier_o[i+1][1] = self.customer_or[i+1][self.time][1]\n",
        "      \n",
        "      self.time += 1\n",
        "\n",
        "      if self.time >= self.total_time:\n",
        "        done_n = [True] * self.n_agents\n",
        "\n",
        "      self.fps_clock.tick(self.fps)\n",
        "      \n",
        "      \n",
        "      #pygame.display.update()\n",
        "      \n",
        "      #obs_n = dict(zip(self.agents, obs_n))\n",
        "      #reward_n = dict(zip(self.agents, reward_n))\n",
        "      #done_n = dict(zip(self.agents, done_n))\n",
        "      return obs_n, reward_n, done_n, info_n\n",
        "    \n",
        "    def render(self, mode: str = 'human'):\n",
        "\n",
        "        pygame.init()\n",
        "        pygame.display.init()\n",
        "\n",
        "        self.screen.fill((200, 200, 200))\n",
        "        #pygame.draw.polygon(self.screen, (0, 0, 0), ((100, 0), (200, 0), (200, 200), (300, 200), (150, 300), (0, 200), (100, 200)))\n",
        "        #pygame.draw.polygon(self.screen, (0, 0, 0), ((40,32), (56,32), (40, 200), (56, 200), (40, 400), (56, 400), (48,468)))\n",
        "        def draw_arrow(screen, colour, start, end):\n",
        "            pygame.draw.line(screen,colour,start,end,15)\n",
        "            rotation = math.degrees(math.atan2(start[1]-end[1], end[0]-start[0]))+90\n",
        "            pygame.draw.polygon(screen, (0, 0, 0), ((end[0]+20*math.sin(math.radians(rotation)), end[1]+20*math.cos(math.radians(rotation))), (end[0]+20*math.sin(math.radians(rotation-120)), end[1]+20*math.cos(math.radians(rotation-120))), (end[0]+20*math.sin(math.radians(rotation+120)), end[1]+20*math.cos(math.radians(rotation+120)))))\n",
        "\n",
        "        draw_arrow(self.screen, (0, 0, 0),[48,48],[48,400])\n",
        "        draw_arrow(self.screen, (0, 0, 0),[16,468],[16,80])\n",
        "\n",
        "        draw_arrow(self.screen, (0, 0, 0),[48,32],[216,200])\n",
        "        draw_arrow(self.screen, (0, 0, 0),[212,228],[80,94])\n",
        "\n",
        "        draw_arrow(self.screen, (0, 0, 0),[48,468],[218,260])\n",
        "        draw_arrow(self.screen, (0, 0, 0),[212,228],[64,420])\n",
        "\n",
        "        draw_arrow(self.screen, (0, 0, 0),[244,228],[452,64])\n",
        "        draw_arrow(self.screen, (0, 0, 0),[452,32],[244,196])\n",
        "\n",
        "        draw_arrow(self.screen, (0, 0, 0),[244,228],[452,436])\n",
        "        draw_arrow(self.screen, (0, 0, 0),[452,468],[244,260])\n",
        "\n",
        "        draw_arrow(self.screen, (0, 0, 0),[244,244],[420,244])\n",
        "        draw_arrow(self.screen, (0, 0, 0),[468,212],[280,212])\n",
        "\n",
        "        draw_arrow(self.screen, (0, 0, 0),[484,228],[484,80])\n",
        "        draw_arrow(self.screen, (0, 0, 0),[452,80],[452,180])\n",
        "\n",
        "        draw_arrow(self.screen, (0, 0, 0),[452,228],[452,400])\n",
        "        draw_arrow(self.screen, (0, 0, 0),[484,468],[484,280])\n",
        "\n",
        "        \n",
        "        pygame.draw.line(self.screen,(self.traffic[1][2]*35,255 - self.traffic[1][2]*35,0),(48,32),(48,468),5)\n",
        "        pygame.draw.line(self.screen,(self.traffic[2][1]*35,255 - self.traffic[2][1]*35,0),(16,32),(16,468),5)\n",
        "        \n",
        "        pygame.draw.line(self.screen,(self.traffic[1][3]*35,255 - self.traffic[1][3]*35,0),(48,32),(244,228),5)\n",
        "        pygame.draw.line(self.screen,(self.traffic[3][1]*35,255 - self.traffic[3][1]*35,0),(16,32),(212,228),5)\n",
        "        \n",
        "        pygame.draw.line(self.screen,(self.traffic[2][3]*35,255 - self.traffic[2][3]*35,0),(48,468),(244,228),5)\n",
        "        pygame.draw.line(self.screen,(self.traffic[3][2]*35,255 - self.traffic[3][2]*35,0),(16,468),(212,228),5)\n",
        "        \n",
        "        pygame.draw.line(self.screen,(self.traffic[3][4]*35,255 - self.traffic[3][4]*35,0),(244,228),(484,32),5)\n",
        "        pygame.draw.line(self.screen,(self.traffic[4][3]*35,255 - self.traffic[4][3]*35,0),(212,228),(452,32),5)\n",
        "        \n",
        "        pygame.draw.line(self.screen,(self.traffic[3][6]*35,255 - self.traffic[3][6]*35,0),(244,228),(484,468),5)\n",
        "        pygame.draw.line(self.screen,(self.traffic[3][6]*35,255 - self.traffic[3][6]*35,0),(212,228),(452,468),5)\n",
        "        \n",
        "        pygame.draw.line(self.screen,(self.traffic[3][5]*35,255 - self.traffic[3][5]*35,0),(244,244),(468,244),5)\n",
        "        pygame.draw.line(self.screen,(self.traffic[5][3]*35,255 - self.traffic[5][3]*35,0),(235,212),(468,212),5)\n",
        "        \n",
        "        pygame.draw.line(self.screen,(self.traffic[5][4]*35,255 - self.traffic[5][4]*35,0),(484,228),(484,32),5)\n",
        "        pygame.draw.line(self.screen,(self.traffic[4][5]*35,255 - self.traffic[4][5]*35,0),(452,228),(452,32),5)\n",
        "        \n",
        "        pygame.draw.line(self.screen,(self.traffic[5][6]*35,255 - self.traffic[5][6]*35,0),(452,228),(452,468),5)\n",
        "        pygame.draw.line(self.screen,(self.traffic[6][5]*35,255 - self.traffic[6][5]*35,0),(484,228),(484,468),5)\n",
        "        \n",
        "        \n",
        "        self.screen.blit(self.img1, (0,0))\n",
        "        self.screen.blit(self.img2, (0,436))\n",
        "        self.screen.blit(self.img3, (200,200))\n",
        "        self.screen.blit(self.img4, (436,0))\n",
        "        self.screen.blit(self.img5, (436,186))\n",
        "        self.screen.blit(self.img6, (436,436))\n",
        "        self.screen.blit(self.img1, (0,0))\n",
        "\n",
        "        for i in range(self.n_agents):\n",
        "            self.screen.blit(self.ag[i], (self.xy[i+1][0],self.xy[i+1][1]))\n",
        "\n",
        "        pygame.event.pump()\n",
        "        pygame.display.update()\n",
        "        #pygame.image.save(self.screen, \"screenshot\"+str(self.time)+\".jpg\")\n",
        "        \n",
        "        self.traffic = np.array([[0,0,0,0,0,0,0],\n",
        "                             [0,0,np.random.randint(1,3),np.random.randint(2,7),0,0,0],\n",
        "                             [0,np.random.randint(1,3),0,np.random.randint(2,5),0,0,0],\n",
        "                             [0,np.random.randint(2,7),np.random.randint(2,5),0,np.random.randint(3,7),np.random.randint(4,5),np.random.randint(1,3)],\n",
        "                             [0,0,0,np.random.randint(3,7),0,np.random.randint(1,3),0],\n",
        "                             [0,0,0,np.random.randint(4,5),np.random.randint(1,3),0,np.random.randint(1,2)],\n",
        "                             [0,0,0,np.random.randint(1,3),0,np.random.randint(1,2),0],])\n",
        "    \n",
        "    def reset(self):\n",
        "      \n",
        "      self.traffic = np.array([[0,0,0,0,0,0,0],\n",
        "                             [0,0,np.random.randint(1,3),np.random.randint(2,7),0,0,0],\n",
        "                             [0,np.random.randint(1,3),0,np.random.randint(2,5),0,0,0],\n",
        "                             [0,np.random.randint(2,7),np.random.randint(2,5),0,np.random.randint(3,7),np.random.randint(4,5),np.random.randint(1,3)],\n",
        "                             [0,0,0,np.random.randint(3,7),0,np.random.randint(1,3),0],\n",
        "                             [0,0,0,np.random.randint(4,5),np.random.randint(1,3),0,np.random.randint(1,2)],\n",
        "                             [0,0,0,np.random.randint(1,3),0,np.random.randint(1,2),0],])\n",
        "      \n",
        "      ti = 0\n",
        "      ord = np.random.poisson(10, size=(self.n_supplier,))\n",
        "      ti += max(ord)\n",
        "\n",
        "      while ti < self.total_time:\n",
        "        ord = np.random.poisson(10, size=(self.n_supplier,))\n",
        "        for i in range(self.n_supplier):\n",
        "          self.customer_or[i+1][ti][0] = np.random.choice([4,5,6])\n",
        "          self.customer_or[i+1][ti][1] = np.random.randint(4,10)\n",
        "        ti += max(ord)\n",
        "\n",
        "      obs_n = []\n",
        "      self.agent_o = []\n",
        "      self.agent_d = []\n",
        "      self.time = 0\n",
        "\n",
        "      for i, agent in enumerate(self.agents):\n",
        "        p = np.random.randint(1,self.n_customer + self.n_hub + self.n_supplier)\n",
        "        self.agent_o.append(p)\n",
        "        self.agent_d.append(p)\n",
        "        ob = np.hstack([\n",
        "            0,\n",
        "            0,\n",
        "            0,\n",
        "            0,\n",
        "            self.agent_v[i],\n",
        "            p,\n",
        "            p,\n",
        "            self.agent_pr[i],\n",
        "            0,\n",
        "            0,\n",
        "            0,\n",
        "            0,\n",
        "        ])\n",
        "        self.xy[i+1][0] += self.x[p]\n",
        "        self.xy[i+1][1] += self.y[p]\n",
        "        \n",
        "        obs_n.append(ob)\n",
        "\n",
        "      #obs_n = dict(zip(self.agents, obs_n))\n",
        "      return obs_n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = MultiAgentEnv()"
      ],
      "metadata": {
        "id": "orSKJsQB-XFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "gjFgqmiubsPy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b098eb9a-1626-4f68-f70b-ac4cd78f2166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.8/dist-packages (0.13.6)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.8/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.19.6)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.1.29)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.8/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (1.0.11)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (1.9.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.8/dist-packages (from GitPython>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import random\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from ma_gym.wrappers import Monitor\n",
        "\n",
        "USE_WANDB = True  # if enabled, logs data on wandb server\n",
        "\n",
        "\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, buffer_limit):\n",
        "        self.buffer = collections.deque(maxlen=buffer_limit)\n",
        "\n",
        "    def put(self, transition):\n",
        "        self.buffer.append(transition)\n",
        "\n",
        "    def sample(self, n):\n",
        "        mini_batch = random.sample(self.buffer, n)\n",
        "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
        "\n",
        "        for transition in mini_batch:\n",
        "            s, a, r, s_prime, done = transition\n",
        "            s_lst.append(s)\n",
        "            a_lst.append(a)\n",
        "            r_lst.append(r)\n",
        "            s_prime_lst.append(s_prime)\n",
        "            done_mask_lst.append((np.ones(len(done)) - done).tolist())\n",
        "\n",
        "        return torch.tensor(s_lst, dtype=torch.float), \\\n",
        "               torch.tensor(a_lst, dtype=torch.float), \\\n",
        "               torch.tensor(r_lst, dtype=torch.float), \\\n",
        "               torch.tensor(s_prime_lst, dtype=torch.float), \\\n",
        "               torch.tensor(done_mask_lst, dtype=torch.float)\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "\n",
        "class QNet(nn.Module):\n",
        "    def __init__(self, observation_space, action_space):\n",
        "        super(QNet, self).__init__()\n",
        "        self.num_agents = len(observation_space)\n",
        "        for agent_i in range(self.num_agents):\n",
        "            n_obs = observation_space[agent_i].shape[0]\n",
        "            setattr(self, 'agent_{}'.format(agent_i), nn.Sequential(nn.Linear(n_obs, 128),\n",
        "                                                                    nn.ReLU(),\n",
        "                                                                    nn.Linear(128, 64),\n",
        "                                                                    nn.ReLU(),\n",
        "                                                                    nn.Linear(64, action_space[agent_i].n)))\n",
        "\n",
        "    def forward(self, obs):\n",
        "        q_values = [torch.empty(obs.shape[0], )] * self.num_agents\n",
        "        for agent_i in range(self.num_agents):\n",
        "            q_values[agent_i] = getattr(self, 'agent_{}'.format(agent_i))(obs[:, agent_i, :]).unsqueeze(1)\n",
        "\n",
        "        return torch.cat(q_values, dim=1)\n",
        "\n",
        "    def sample_action(self, obs, epsilon):\n",
        "        out = self.forward(obs)\n",
        "        mask = (torch.rand((out.shape[0],)) <= epsilon)\n",
        "        action = torch.empty((out.shape[0], out.shape[1],))\n",
        "        action[mask] = torch.randint(0, out.shape[2], action[mask].shape).float()\n",
        "        action[~mask] = out[~mask].argmax(dim=2).float()\n",
        "        return action\n",
        "\n",
        "\n",
        "def train(q, q_target, memory, optimizer, gamma, batch_size, update_iter=10):\n",
        "    for _ in range(update_iter):\n",
        "        s, a, r, s_prime, done_mask = memory.sample(batch_size)\n",
        "\n",
        "        q_out = q(s)\n",
        "        q_a = q_out.gather(2, a.unsqueeze(-1).long()).squeeze(-1)\n",
        "        max_q_prime = q_target(s_prime).max(dim=2)[0]\n",
        "        target = r + gamma * max_q_prime * done_mask\n",
        "        loss = F.smooth_l1_loss(q_a, target.detach())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "def test(env, num_episodes, q):\n",
        "    score = np.zeros(env.n_agents)\n",
        "    for episode_i in range(num_episodes):\n",
        "        state = env.reset()\n",
        "        done = [False for _ in range(env.n_agents)]\n",
        "        while not all(done):\n",
        "            action = q.sample_action(torch.Tensor(state).unsqueeze(0), epsilon=0)[0].data.cpu().numpy().tolist()\n",
        "            next_state, reward, done = env.step(action)\n",
        "            score += np.array(reward)\n",
        "            state = next_state\n",
        "\n",
        "    return sum(score / num_episodes)\n",
        "\n",
        "\n",
        "def main(env_name, lr, gamma, batch_size, buffer_limit, log_interval, max_episodes,\n",
        "         max_epsilon, min_epsilon, test_episodes, warm_up_steps, update_iter, monitor=False):\n",
        "    env = MultiAgentEnv()\n",
        "    test_env = MultiAgentEnv()\n",
        "    if monitor:\n",
        "        test_env = Monitor(test_env, directory='recordings/idqn/{}'.format(env_name),\n",
        "                           video_callable=lambda episode_id: episode_id % 50 == 0)\n",
        "    memory = ReplayBuffer(buffer_limit)\n",
        "\n",
        "    q = QNet(env.observation_space, env.action_space)\n",
        "    q_target = QNet(env.observation_space, env.action_space)\n",
        "    q_target.load_state_dict(q.state_dict())\n",
        "    optimizer = optim.Adam(q.parameters(), lr=lr)\n",
        "\n",
        "    score = np.zeros(env.n_agents)\n",
        "    for episode_i in range(max_episodes):\n",
        "        epsilon = max(min_epsilon, max_epsilon - (max_epsilon - min_epsilon) * (episode_i / (0.4 * max_episodes)))\n",
        "        state = env.reset()\n",
        "        done = [False for _ in range(env.n_agents)]\n",
        "        while not all(done):\n",
        "            action = q.sample_action(torch.Tensor(state).unsqueeze(0), epsilon)[0].data.cpu().numpy().tolist()\n",
        "            next_state, reward, done = env.step(action)\n",
        "            memory.put((state, action, (np.array(reward)).tolist(), next_state, np.array(done, dtype=int).tolist()))\n",
        "            score += np.array(reward)\n",
        "            state = next_state\n",
        "\n",
        "        if memory.size() > warm_up_steps:\n",
        "            train(q, q_target, memory, optimizer, gamma, batch_size, update_iter)\n",
        "\n",
        "        if episode_i % log_interval == 0 and episode_i != 0:\n",
        "            q_target.load_state_dict(q.state_dict())\n",
        "            test_score = test(test_env, test_episodes, q)\n",
        "            print(\"#{:<10}/{} episodes , avg train score : {:.1f}, test score: {:.1f} n_buffer : {}, eps : {:.1f}\"\n",
        "                  .format(episode_i, max_episodes, sum(score / log_interval), test_score, memory.size(), epsilon))\n",
        "            if USE_WANDB:\n",
        "                wandb.log({'episode': episode_i, 'test-score': test_score,\n",
        "                           'buffer-size': memory.size(), 'epsilon': epsilon, 'train-score': sum(score / log_interval)})\n",
        "            score = np.zeros(env.n_agents)\n",
        "\n",
        "    env.close()\n",
        "    test_env.close()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    kwargs = {'env_name': 'ma_gym:Switch2-v1',\n",
        "              'lr': 0.0005,\n",
        "              'batch_size': 32,\n",
        "              'gamma': 0.99,\n",
        "              'buffer_limit': 50000,\n",
        "              'log_interval': 20,\n",
        "              'max_episodes': 200,\n",
        "              'max_epsilon': 0.9,\n",
        "              'min_epsilon': 0.1,\n",
        "              'test_episodes': 5,\n",
        "              'warm_up_steps': 2000,\n",
        "              'update_iter': 10,\n",
        "              'monitor': False}\n",
        "    if USE_WANDB:\n",
        "        import wandb\n",
        "\n",
        "        wandb.init(project='minimal-marl', config={'algo': 'idqn', **kwargs}, monitor_gym=True)\n",
        "\n",
        "    main(**kwargs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "iXNDnU3fbQ2U",
        "outputId": "a143917f-01ef-4067-a589-e048250ed29c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:1dyii0rd) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>buffer-size</td><td></td></tr><tr><td>episode</td><td></td></tr><tr><td>epsilon</td><td></td></tr><tr><td>test-score</td><td></td></tr><tr><td>train-score</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>buffer-size</td><td>18100</td></tr><tr><td>episode</td><td>180</td></tr><tr><td>epsilon</td><td>0.1</td></tr><tr><td>test-score</td><td>-1.2</td></tr><tr><td>train-score</td><td>-120.3</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">snowy-voice-13</strong>: <a href=\"https://wandb.ai/uvic_simulation/minimal-marl/runs/1dyii0rd\" target=\"_blank\">https://wandb.ai/uvic_simulation/minimal-marl/runs/1dyii0rd</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221210_081820-1dyii0rd/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:1dyii0rd). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221210_091553-23zr35qk</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/uvic_simulation/minimal-marl/runs/23zr35qk\" target=\"_blank\">ethereal-shape-14</a></strong> to <a href=\"https://wandb.ai/uvic_simulation/minimal-marl\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-1aa917f804bb>:218: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  self.agent_pr[i] += self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n",
            "<ipython-input-49-1aa917f804bb>:219: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  d = self.agent_v[i]/self.dis[self.agent_o[i]][self.agent_d[i]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#20        /200 episodes , avg train score : -5229.4, test score: -176.6 n_buffer : 2100, eps : 0.7\n",
            "#40        /200 episodes , avg train score : -2753.5, test score: 0.0 n_buffer : 4100, eps : 0.5\n",
            "#60        /200 episodes , avg train score : -1315.6, test score: 0.6 n_buffer : 6100, eps : 0.3\n",
            "#80        /200 episodes , avg train score : -511.9, test score: -1.6 n_buffer : 8100, eps : 0.1\n",
            "#100       /200 episodes , avg train score : -179.1, test score: 0.0 n_buffer : 10100, eps : 0.1\n",
            "#120       /200 episodes , avg train score : -185.9, test score: 0.0 n_buffer : 12100, eps : 0.1\n",
            "#140       /200 episodes , avg train score : -159.6, test score: 0.0 n_buffer : 14100, eps : 0.1\n",
            "#160       /200 episodes , avg train score : -175.1, test score: 0.0 n_buffer : 16100, eps : 0.1\n",
            "#180       /200 episodes , avg train score : -173.4, test score: -1.6 n_buffer : 18100, eps : 0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pipreqs"
      ],
      "metadata": {
        "id": "hs2BlArH8JyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pipreqs . "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3JHbJVf8Yhw",
        "outputId": "47986292-b981-4e07-9963-28165894d984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: Successfully saved requirements file in ./requirements.txt\n"
          ]
        }
      ]
    }
  ]
}